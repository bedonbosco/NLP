[`⚙ Tools`](https://github.com/magizbox/underthesea/wiki/English-NLP-Tools) | [`⟰ Publications`](https://github.com/magizbox/underthesea/wiki/English-NLP-Publications) | **`☶ SOTA`** | [`⚛ Services`](https://github.com/magizbox/underthesea/wiki/English-NLP-Services)

## Table of Contents

* [**Preprocess**](#preprocess)
* [**Sentence Boundary Disambiguation**](#sentence-boundary-disambiguation)
* [**Language Detection**](#language-detection)
* [**Spelling Correction**](#spelling-correction)
* [**Word Segmentation**](#word-segmentation)
* [**Part-of-Speech Tagging**](#part-of-speech-tagging)
* [**Chunking**](#chunking)
* [**Parsing**](#parsing)
* [**Representation**](#representation)
* [**Text Classification**](#text-classification)
* [**Sentiment Analysis**](#sentiment-analysis)
* [**Named Entity Recognition**](#named-entity-recognition)
* [**Relationship Extraction**](#relationship-extraction)
* [**Coreference Resolution**](#coreference-resolution)
* [**Slotfilling**](#slotfilling)
* [**Entity Linking**](#entity-linking)
* [**Knowledge Representation and Reasoning**](#knowledge-representation-and-reasoning)
* [**Semantics**](#semantics)
* [**Semantic Role Labeling**](#semantic-role-labeling)
* [**Textual Entailment**](#textual-entailment)
* [**Question Answering**](#question-answering)
* [**Language Generation**](#language-generation)
* [**Machine Translation**](#machine-translation)
* [**Automatic Summarization**](#automatic-summarization)
* [**Automatic Speech Recognition**](#automatic-speech-recognition)
* [**Text To Speech**](#text-to-speech)
* [**Dialog Systems and Chatbots**](#dialogue-systems-and-chatbots)
* [**Optical Text Recognition**](#optical-text-recognition)
* [**Resources**](#resources)
* [**Miscellaneous**](#miscellaneous)

## Part-of-Speech Tagging

[`⚙ Tools`](https://github.com/magizbox/underthesea/wiki/English-NLP-Tools#part-of-speech-tagging) | [`⟰ Publications`](https://github.com/magizbox/underthesea/wiki/English-NLP-Publications#part-of-speech-tagging) | **`☶ SOTA`** | [`⚛ Services`](https://github.com/magizbox/underthesea/wiki/English-NLP-Services#part-of-speech-tagging)

**[Wall Street Journal Section of Penn Treebank](https://github.com/magizbox/underthesea/wiki/POS-Tagging-Task:-WSJ-PTB)** <sub><sup>8 results collected</sup></sub>

The Penn Treebank (PTB) project selected 2,499 stories from a three year Wall Street Journal (WSJ) collection of 98,732 stories for syntactic annotation. These 2,499 stories have been distributed in both Treebank-2 (LDC1999T42) and Treebank-3 (LDC1999T42) releases of PTB. Treebank-2 includes the raw text for each story. Three "map" files are available in a compressed file (pennTB_tipster_wsj_map.tar.gz) as an additional download for users who have licensed Treebank-2 and provide the relation between the 2,499 PTB filenames and the corresponding WSJ DOCNO strings in TIPSTER.

## Chunking

[`⚙ Tools`](https://github.com/magizbox/underthesea/wiki/English-NLP-Tools#chunking) | [`⟰ Publications`](https://github.com/magizbox/underthesea/wiki/English-NLP-Publications#chunking) | **`☶ SOTA`** | [`⚛ Services`](https://github.com/magizbox/underthesea/wiki/English-NLP-Services#chunking)

**[Wall Street Journal Section of Penn Treebank](https://github.com/magizbox/underthesea/wiki/Chunking-Task:-WSJ-PTB)** <sub><sup>3 results collected</sup></sub>

The Penn Treebank (PTB) project selected 2,499 stories from a three year Wall Street Journal (WSJ) collection of 98,732 stories for syntactic annotation. These 2,499 stories have been distributed in both Treebank-2 (LDC1999T42) and Treebank-3 (LDC1999T42) releases of PTB. Treebank-2 includes the raw text for each story. Three "map" files are available in a compressed file (pennTB_tipster_wsj_map.tar.gz) as an additional download for users who have licensed Treebank-2 and provide the relation between the 2,499 PTB filenames and the corresponding WSJ DOCNO strings in TIPSTER.

## Representation

[`⚙ Tools`](https://github.com/magizbox/underthesea/wiki/English-NLP-Tools#representation) | [`⟰ Publications`](https://github.com/magizbox/underthesea/wiki/English-NLP-Publications#representation) | **`☶ SOTA`** | [`⚛ Services`](https://github.com/magizbox/underthesea/wiki/English-NLP-Services#representation)

**[Simverb-3500-Dataset](https://github.com/magizbox/underthesea/wiki/DATA-SIMVERB-3500)** <sub><sup>5 results collected</sup></sub>

SimVerb-3500 (Gerz ‎2016) is an evaluation resource that provides human ratings for the similarity of 3,500 verb pairs. SimVerb-3500 covers all normed verb types from the USF free-association database, providing at least three examples for every VerbNet class.

**[SimLex-999 Dataset](https://github.com/magizbox/underthesea/wiki/DATA-SIMLEX-999)** <sub><sup>14 results collected</sup></sub>

SimLex-999 (Hill 2014) is a gold standard resource for the evaluation of models that learn the meaning of words and concepts. SimLex-999 provides a way of measuring how well models capture similarity, rather than relatedness or association.

**[Rare Word (RW) Dataset](https://github.com/magizbox/underthesea/wiki/DATA-RAREWORD)** <sub><sup>15 results collected</sup></sub>

Most existing word similarity datasets contain frequent words and few of them possesses enough rare or morphologically complex words that we could really attest the expressiveness of our morphoRNN models. Good embedding in general should be able to learn useful representations for not just frequent words but also rare ones. Rare Word (Luong 2013) is dataset focusing on rare words to complement existing ones.

**[WordSim353 Dataset](https://github.com/magizbox/underthesea/wiki/DATA-WORDSIM-353)** <sub><sup>22 results collected</sup></sub>

The WordSimilarity-353 Test Collection (Gabrilovich 2002) contains two sets of English word pairs along with human-assigned similarity judgements. The collection can be used to train and/or test computer algorithms implementing semantic similarity measures.

## Text Classification

[`⚙ Tools`](https://github.com/magizbox/underthesea/wiki/English-NLP-Tools#text-classification) | [`⟰ Publications`](https://github.com/magizbox/underthesea/wiki/English-NLP-Publications#text-classification) | **`☶ SOTA`** | [`⚛ Services`](https://github.com/magizbox/underthesea/wiki/English-NLP-Services#text-classification)

**[AG’s news corpus](https://github.com/magizbox/underthesea/wiki/DATA-AGNEWS)** <sub><sup>22 results collected</sup></sub>

AG (GM Del Corso et al. 2005) is a collection of more than 1 million news articles. News articles have been gathered from more than 2000  news sources by ComeToMyHead in more than 1 year of activity. 

**[IMDB dataset](https://github.com/magizbox/underthesea/wiki/DATA-IMDB)** <sub><sup>11 results collected</sup></sub>

The Internet Movie Database (IMDB) is an online database containing information and statistics about movies, TV shows and video games as well as actors, directors and other film industry professionals. This information can include lists of cast and crew members, movie release dates and box office information, plot summaries, trailers, actor and director biographies and other trivia.

**[TREC question dataset](https://github.com/magizbox/underthesea/wiki/DATA-TREC)** <sub><sup>6 results collected</sup></sub>

Task involves classifying a question into 6 question types (whether the question is about person,
location, numeric information, etc.) (Li et al. 2002)

## Sentiment Analysis

[`⚙ Tools`](https://github.com/magizbox/underthesea/wiki/English-NLP-Tools#sentiment-analysis) | [`⟰ Publications`](https://github.com/magizbox/underthesea/wiki/English-NLP-Publications#sentiment-analysis) | **`☶ SOTA`** | [`⚛ Services`](https://github.com/magizbox/underthesea/wiki/English-NLP-Services#sentiment-analysis)

**[SemEval-2017 Task 5](https://github.com/magizbox/underthesea/wiki/SemEval-2017-Task-5)** <sub><sup>8 results collected</sup></sub>

SemEval 2017 Task 5: The proposed task aims at catalysing discussions around approaches of semantic interpretation of financial texts by targeting a concrete sentiment analysis task, which identifies bullish (optimistic; believing that the stock price will increase) and bearish (pessimistic; believing that the stock price will decline) sentiment associated with companies and stocks.

**[SemEval-2016 Task 5](https://github.com/magizbox/underthesea/wiki/SemEval-2016-Task-5)** <sub><sup>245 results collected</sup></sub>

The SemEval ABSA task for 2016 (SE-ABSA16) gives the opportunity to participants to further experiment with English data (reviews) from the domains of SE-ABSA15 (laptops, restaurants, hotels) by providing new test datasets. In addition, SE-ABSA16 will also provide datasets in other than English languages. For each domain (e.g. restaurants) a common set of annotation guidelines will be used across all languages. Furthermore, SE-ABSA16 includes text-level annotations along with a suitable evaluation methodology.

**[SemEval-2015 Task 12](https://github.com/magizbox/underthesea/wiki/SemEval-2015-Task-12)** <sub><sup>32 results collected</sup></sub>

SemEval-2015 Task 12, a continuation of SemEval-2014 Task 4, aimed to foster research beyond sentence- or text-level sentiment classification towards Aspect Based Sentiment Analysis. The goal is to identify opinions expressed about specific entities (e.g., laptops) and their aspects (e.g., price). The task provided manually annotated reviews
in three domains (restaurants, laptops and hotels), and a common evaluation procedure. It attracted 93 submissions from 16 teams.

**[SemEval-2014 Task 4](https://github.com/magizbox/underthesea/wiki/SemEval-2014-Task-4)** <sub><sup>16 results collected</sup></sub>

Sentiment analysis is increasingly viewed as a vital task both from an academic and a commercial standpoint. The majority of current approaches, however, attempt to detect the overall polarity of a sentence, paragraph, or text span, regardless of the entities mentioned (e.g., laptops, restaurants) and their aspects (e.g., battery, screen; food, service). By contrast, this task is concerned with aspect based sentiment analysis (ABSA), where the goal is to identify the aspects of given target entities and the sentiment expressed towards each aspect. Datasets consisting of customer reviews with human-authored annotations identifying the mentioned aspects of the target entities and the sentiment polarity of each aspect will be provided.

**[Stanford Sentiment Treebank](https://github.com/magizbox/underthesea/wiki/DATA-SST)** <sub><sup>15 results collected</sup></sub>

Stanford Sentiment Treebank—an extension of MR but with train/dev/test splits provided and fine-grained labels (very positive, positive, neutral, negative, very negative), re-labeled by Socher et al. (2013).

**[MPQA Opinion Corpus](https://github.com/magizbox/underthesea/wiki/DATA-MPQA)** <sub><sup>9 results collected</sup></sub>

The MPQA Opinion Corpus (Wiebe et al. 2005) contains news articles from a wide variety of news sources manually annotated for opinions and other private states (i.e., beliefs, emotions, sentiments, speculations, etc.)

## Named Entity Recognition

[`⚙ Tools`](https://github.com/magizbox/underthesea/wiki/English-NLP-Tools#named-entity-recognition) | [`⟰ Publications`](https://github.com/magizbox/underthesea/wiki/English-NLP-Publications#named-entity-recognition) | **`☶ SOTA`** | [`⚛ Services`](https://github.com/magizbox/underthesea/wiki/English-NLP-Services#named-entity-recognition)

**[CoNLL-2012 Shared Task: Language-Independent Named Entity Recognition](https://github.com/magizbox/underthesea/wiki/TASK-CONLL-2012)** <sub><sup>4 results collected</sup></sub>

The OntoNotes Release 5.0 shared task deals with language-independent named entity recognition as well (English, Chinese, and Arabi).

**[CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition](https://github.com/magizbox/underthesea/wiki/TASK-CONLL-2003)** <sub><sup>3 results collected</sup></sub>

The CoNLL-2003 (Sang et al. 2003) shared task deals with language-independent named entity recognition as well (English and German).

## Semantic Role Labeling

[`⚙ Tools`](https://github.com/magizbox/underthesea/wiki/English-NLP-Tools#semantic-role-labeling) | [`⟰ Publications`](https://github.com/magizbox/underthesea/wiki/English-NLP-Publications#semantic-role-labeling) | **`☶ SOTA`** | [`⚛ Services`](https://github.com/magizbox/underthesea/wiki/English-NLP-Services#semantic-role-labeling)

## Textual Entailment

[`⚙ Tools`](https://github.com/magizbox/underthesea/wiki/English-NLP-Tools#textual-entailment) | [`⟰ Publications`](https://github.com/magizbox/underthesea/wiki/English-NLP-Publications#textual-entailment) | **`☶ SOTA`** | [`⚛ Services`](https://github.com/magizbox/underthesea/wiki/English-NLP-Services#textual-entailment)

**[The Stanford Natural Language Inference (SNLI) Corpus](https://github.com/magizbox/underthesea/wiki/DATA-SNLI)** <sub><sup>10 results collected</sup></sub>

The SNLI corpus (Bowman 2015) is a collection of 570k human-written English sentence pairs manually labeled for balanced classification with the labels entailment, contradiction, and neutral, supporting the task of natural language inference (NLI), also known as recognizing textual entailment (RTE). We aim for it to serve both as a benchmark for evaluating representational systems for text, especially including those induced by representation learning methods, as well as a resource for developing NLP models of any kind.

## Question Answering

[`⚙ Tools`](https://github.com/magizbox/underthesea/wiki/English-NLP-Tools#question-answering) | [`⟰ Publications`](https://github.com/magizbox/underthesea/wiki/English-NLP-Publications#question-answering) | **`☶ SOTA`** | [`⚛ Services`](https://github.com/magizbox/underthesea/wiki/English-NLP-Services#question-answering)

**[Stanford Question Answering Dataset (SQuAD) dataset](https://github.com/magizbox/underthesea/wiki/DATA-SQUAD)** <sub><sup>6 results collected</sup></sub>

Stanford Question Answering Dataset (SQuAD) (Rajpurkar 2016) is a new reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage.

## Machine Translation

[`⚙ Tools`](https://github.com/magizbox/underthesea/wiki/English-NLP-Tools#machine-translation) | [`⟰ Publications`](https://github.com/magizbox/underthesea/wiki/English-NLP-Publications#machine-translation) | **`☶ SOTA`** | [`⚛ Services`](https://github.com/magizbox/underthesea/wiki/English-NLP-Services#machine-translation)

**[Multi30k dataset](https://github.com/magizbox/underthesea/wiki/DATA-MULTI30k)** <sub><sup>4 results collected</sup></sub>

Multi30K dataset (Elliott 2017) to stimulate multilingual multimodal research.  This dataset extends the Flickr30K dataset with German translations created by professional translators over a subset of the English descriptions, and German descriptions crowdsourced independently of the original English descriptions. We describe the data and outline how it can be used for multilingual image description and multimodal machine translation, but we anticipate the data will be useful for a broader range of tasks.